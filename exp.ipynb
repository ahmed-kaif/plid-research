{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "974ec202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20687d",
   "metadata": {},
   "source": [
    "## Data Loading and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c37c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (349, 25)\n",
      "Cleaned Feature Matrix X shape: (78, 20)\n",
      "Target Vector Y shape: (78,)\n",
      "X_train shape: (62, 20), Y_train shape: (62,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('plid.csv')\n",
    "\n",
    "TARGET_COLUMNS = ['Post operative ODI',\n",
    "    'Post operative NRS back pain',\n",
    "    'Surgery outcome according to Macnab criteria',\n",
    "    'Post operative NRS leg pain']\n",
    "\n",
    "print(f\"Original DataFrame shape: {df.shape}\")\n",
    "\n",
    "# %%\n",
    "\n",
    "# Apply Listwise Deletion (LWD)\n",
    "# FIX: Ensure subset uses a list [TARGET_COLUMNS[0]]\n",
    "df_lwd = df.dropna(subset=[TARGET_COLUMNS[0]]).copy() \n",
    "\n",
    "# Define feature matrix X (drop all targets)\n",
    "X = df_lwd.drop(columns=TARGET_COLUMNS) \n",
    "X.drop(columns=['Timestamp'], inplace=True, errors='ignore')  # Drop Timestamp if exists\n",
    "\n",
    "# FIX: Define Y as the SINGLE target column for prediction\n",
    "Y = df_lwd[TARGET_COLUMNS[0]] \n",
    "\n",
    "# Split the LWD data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# %%\n",
    "print(f\"Cleaned Feature Matrix X shape: {X.shape}\")\n",
    "print(f\"Target Vector Y shape: {Y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26f4494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Verification ---\n",
      "Total features in X: 20\n",
      "Features present in X that SHOULD NOT be targets: set()\n",
      "Number of columns in X with ANY NaN values: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Feature Verification ---\")\n",
    "print(f\"Total features in X: {len(X.columns)}\")\n",
    "print(f\"Features present in X that SHOULD NOT be targets: {set(TARGET_COLUMNS).intersection(X.columns)}\")\n",
    "print(f\"Number of columns in X with ANY NaN values: {X.isna().any().sum()}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd31545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a80de8",
   "metadata": {},
   "source": [
    "## Imputation Pipeline & Column Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa29febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal Categorical Features: ['Age', 'Annulus', 'Level of Disc Prolapse', 'Occupation', 'Operative Findings', 'Sex', 'Type of Operation']\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Feature Sets\n",
    "MNAR_CATEGORICAL_FEATURES = ['Low back pain',\n",
    "        'Low back pain with Sciatica', 'Bowel Bladder Involvement',\n",
    "        'Straight Leg Raising Test', 'Femoral Stretching Test',\n",
    "        'Sensory Involvement', 'Motor involvement', 'Knee Jerk', 'Ankle Jerk']\n",
    "NUMERICAL_FEATURES = ['Pre operative ODI',\n",
    "        'Pre operative NRS back pain',\n",
    "        'Pre operative NRS leg pain']\n",
    "# All remaining object columns are treated as Nominal Categorical\n",
    "NOMINAL_CATEGORICAL_FEATURES = list(\n",
    "    X.select_dtypes(include=['object']).columns.difference(MNAR_CATEGORICAL_FEATURES)\n",
    ")\n",
    "# Ensure any unlisted numerical columns are also handled as remainder='drop' \n",
    "# or included here. We will ensure all feature columns are accounted for:\n",
    "# Let's add any remaining numerical columns (like 'Age' in the mock data) to NUMERICAL_FEATURES\n",
    "numerical_cols_remaining = list(\n",
    "    X.select_dtypes(include=np.number).columns.difference(NUMERICAL_FEATURES)\n",
    ")\n",
    "NUMERICAL_FEATURES.extend(numerical_cols_remaining)\n",
    "\n",
    "print(f\"Nominal Categorical Features: {NOMINAL_CATEGORICAL_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3de9e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Unaccounted Feature Identification ---\n",
      "Total features defined in pipelines: 20\n",
      "Total features in X: 20\n",
      "\n",
      "FEATURES THAT WERE DROPPED:\n",
      "set()\n",
      "\n",
      "--- Diagnostic Strategy ---\n",
      "The issue is not feature dropping. Proceed to Imputation Bias Check (using simplified imputation).\n"
     ]
    }
   ],
   "source": [
    "all_defined_features = set(MNAR_CATEGORICAL_FEATURES + NUMERICAL_FEATURES)\n",
    "\n",
    "# NOTE: We need to recreate NOMINAL_CATEGORICAL_FEATURES exactly as you defined it\n",
    "# to ensure it's accurate:\n",
    "NOMINAL_CATEGORICAL_FEATURES = list(\n",
    "    X.select_dtypes(include=['object']).columns.difference(MNAR_CATEGORICAL_FEATURES)\n",
    ")\n",
    "all_defined_features.update(NOMINAL_CATEGORICAL_FEATURES)\n",
    "\n",
    "\n",
    "all_X_features = set(X.columns)\n",
    "\n",
    "# 2. Find the difference: features present in X but not in any list\n",
    "unaccounted_features = all_X_features.difference(all_defined_features)\n",
    "\n",
    "print(\"--- Unaccounted Feature Identification ---\")\n",
    "print(f\"Total features defined in pipelines: {len(all_defined_features)}\")\n",
    "print(f\"Total features in X: {len(all_X_features)}\")\n",
    "print(f\"\\nFEATURES THAT WERE DROPPED:\")\n",
    "print(unaccounted_features)\n",
    "\n",
    "print(\"\\n--- Diagnostic Strategy ---\")\n",
    "if len(unaccounted_features) > 0:\n",
    "    print(\"ACTION: You must assign these dropped features to one of your existing pipelines (likely 'numerical_pipeline' or 'nominal_pipeline').\")\n",
    "else:\n",
    "    print(\"The issue is not feature dropping. Proceed to Imputation Bias Check (using simplified imputation).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "537b2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Build Component Pipelines\n",
    "# Pipeline for MNAR categorical data (Impute 'Unknown', then One Hot Encode)\n",
    "# MNAR features are imputed with a constant 'Unknown' value to explicitly\n",
    "# capture the missingness, treating it as its own category.\n",
    "mnar_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pipeline for Numerical data (Impute Median, then Scale)\n",
    "# Numerical features are imputed with the median to be robust to outliers,\n",
    "# and then scaled to have zero mean and unit variance.\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for Nominal categorical data (Impute Mode, then One Hot Encode)\n",
    "# Nominal features are imputed with the mode (most frequent) and then One-Hot Encoded.\n",
    "nominal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "transformer_list = [\n",
    "    ('mnar_cat_proc', mnar_pipeline, MNAR_CATEGORICAL_FEATURES),\n",
    "    ('num_proc', numerical_pipeline, NUMERICAL_FEATURES),\n",
    "    ('nom_cat_proc', nominal_pipeline, NOMINAL_CATEGORICAL_FEATURES)\n",
    "]\n",
    "\n",
    "# 3. Integrate components using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformer_list,\n",
    "    # remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3462f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Simplified Imputation Ridge Pipeline...\n",
      "\n",
      "--- Simplified Imputation Test Result (Ridge) ---\n",
      "R-squared (R2): -1.595\n"
     ]
    }
   ],
   "source": [
    "# 1. Combine all categorical features\n",
    "ALL_CATEGORICAL_FEATURES = MNAR_CATEGORICAL_FEATURES + NOMINAL_CATEGORICAL_FEATURES\n",
    "\n",
    "# 2. Define Simplified Categorical Pipeline (Impute Mode, then One Hot Encode)\n",
    "# We are replacing the MNAR strategy with simple mode imputation for all categorical data.\n",
    "simplified_cat_pipeline = Pipeline(steps=[\n",
    "    # Impute mode for ALL categorical features\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3. Build new transformer list\n",
    "simplified_transformer_list = [\n",
    "    ('cat_proc', simplified_cat_pipeline, ALL_CATEGORICAL_FEATURES),\n",
    "    # Reuse the existing numerical pipeline\n",
    "    ('num_proc', numerical_pipeline, NUMERICAL_FEATURES) \n",
    "]\n",
    "\n",
    "# 4. Integrate components using ColumnTransformer\n",
    "simple_preprocessor = ColumnTransformer(\n",
    "    transformers=simplified_transformer_list,\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# 5. Build the new pipeline (using Ridge for stability)\n",
    "ridge_simple_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', simple_preprocessor),\n",
    "    ('regressor', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Fitting Simplified Imputation Ridge Pipeline...\")\n",
    "ridge_simple_pipeline.fit(X_train, Y_train) # Ensure Y is single-column\n",
    "\n",
    "# 6. Evaluate\n",
    "Y_pred_simple = ridge_simple_pipeline.predict(X_test)\n",
    "r2_simple = r2_score(Y_test, Y_pred_simple)\n",
    "\n",
    "print(f\"\\n--- Simplified Imputation Test Result (Ridge) ---\")\n",
    "print(f\"R-squared (R2): {r2_simple:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae22131",
   "metadata": {},
   "source": [
    "## ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26beb7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest Pipeline (Single-Target: 'Post operative ODI')...\n",
      "Pipeline fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator (e.g., Random Forest)\n",
    "rfr_estimator = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)\n",
    "\n",
    "# Build the final end-to-end pipeline\n",
    "rfr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', rfr_estimator)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "print(\"Fitting Random Forest Pipeline (Single-Target: 'Post operative ODI')...\")\n",
    "rfr_pipeline.fit(X_train, Y_train)\n",
    "print(\"Pipeline fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e22662",
   "metadata": {},
   "source": [
    "## Training, Prediction, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f411f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation for 'Post operative ODI' ---\n",
      "R-squared (R2): -0.889\n",
      "Root Mean Squared Error (RMSE): 16.25 (ODI Points)\n",
      "Mean Absolute Error (MAE): 11.85 (ODI Points)\n",
      "\n",
      "Permutation Feature Importance (Top 5):\n",
      "Low back pain_Unknown         : 0.0684\n",
      "Sensory Involvement_Unknown   : 0.0228\n",
      "Low back pain with Sciatica_Left: 0.0090\n",
      "Straight Leg Raising Test_Not Restricted: 0.0048\n",
      "Low back pain with Sciatica_Both: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "Y_pred = rfr_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics (now applied to the single target vector Y_test)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "rmse = root_mean_squared_error(Y_test, Y_pred) # No need for squared=False if using function\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "print(f\"--- Model Evaluation for 'Post operative ODI' ---\")\n",
    "print(f\"R-squared (R2): {r2:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} (ODI Points)\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} (ODI Points)\")\n",
    "\n",
    "# --- Interpretation Example: Permutation Importance ---\n",
    "# Compute Permutation Importance on the test set\n",
    "r_importances = permutation_importance(\n",
    "    rfr_pipeline, X_test, Y_test, n_repeats=10, random_state=42, scoring='r2'\n",
    ")\n",
    "\n",
    "# Organize and display feature importance\n",
    "# Get feature names from the preprocessor step\n",
    "feature_names = rfr_pipeline['preprocessor'].get_feature_names_out() \n",
    "sorted_idx = r_importances.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"\\nPermutation Feature Importance (Top 5):\")\n",
    "for i in sorted_idx[:5]:\n",
    "    # FIX: Use the processed feature names for accurate labeling\n",
    "    print(f\"{feature_names[i]:<30}: {r_importances.importances_mean[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e55ebd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Pipeline fitted successfully.\n",
      "--- Linear Regression Model Evaluation for 'Post operative ODI' ---\n",
      "R-squared (R2): -2.262\n",
      "Root Mean Squared Error (RMSE): 21.35 (ODI Points)\n",
      "Mean Absolute Error (MAE): 16.82 (ODI Points)\n"
     ]
    }
   ],
   "source": [
    "# create linearRegression pipeline\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=0.9))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train, Y_train)\n",
    "print(\"Linear Regression Pipeline fitted successfully.\")\n",
    "\n",
    "Y_pred_lr = lr_pipeline.predict(X_test)\n",
    "print(f\"--- Linear Regression Model Evaluation for 'Post operative ODI' ---\")\n",
    "r2_lr = r2_score(Y_test, Y_pred_lr)\n",
    "rmse_lr = root_mean_squared_error(Y_test, Y_pred_lr)\n",
    "mae_lr = mean_absolute_error(Y_test, Y_pred_lr)\n",
    "print(f\"R-squared (R2): {r2_lr:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lr:.2f} (ODI Points)\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_lr:.2f} (ODI Points)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
